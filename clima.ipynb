{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cargando dimensiones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMENSION CLIENTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "# Configuración de la conexión a la base de datos\n",
    "conexion = psycopg2.connect(\n",
    "    dbname=\"Parada_1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"1234\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Ejecutar la consulta para insertar datos en la tabla `dim_cliente`\n",
    "cursor.execute(\"\"\"\n",
    "    INSERT INTO \"CuboMultidimensional\".dim_cliente (tipo_cliente)\n",
    "    SELECT DISTINCT Tipo_de_Cliente\n",
    "    FROM transaccional.Clientes;\n",
    "\"\"\")\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexión\n",
    "conexion.commit()\n",
    "cursor.close()\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMENSION PARADA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### **Cargamos dimension parada**\n",
    "# Configuración de la conexión a la base de datos\n",
    "conexion = psycopg2.connect(\n",
    "    dbname=\"Parada_1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"1234\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Ejecutar la consulta para insertar datos en la tabla `dim_parada`\n",
    "cursor.execute(\"\"\"  \n",
    "    INSERT INTO \"CuboMultidimensional\".dim_parada (parada, barrio, localidad, provincia)\n",
    "    SELECT DISTINCT \n",
    "        p.Nombre AS parada,\n",
    "        u.Barrio AS barrio,\n",
    "        u.Localidad AS localidad,\n",
    "        u.Provincia AS provincia\n",
    "    FROM transaccional.Parada p\n",
    "    JOIN transaccional.Ubicacion u ON p.ID_Ubicacion = u.ID_Ubicacion;\n",
    "\"\"\")\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexión\n",
    "conexion.commit()\n",
    "cursor.close()\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMENSION COLECTIVO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### **Cargamos dimension colectivo**\n",
    "# Configuración de la conexión a la base de datos\n",
    "conexion = psycopg2.connect(\n",
    "    dbname=\"Parada_1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"1234\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Ejecutar la consulta para insertar datos en la tabla `dim_colectivo`\n",
    "cursor.execute(\"\"\"\n",
    "    INSERT INTO \"CuboMultidimensional\".dim_colectivo (numero_colectivo, matricula)\n",
    "    SELECT DISTINCT CAST(li.nombre AS VARCHAR), c.Matricula\n",
    "    FROM transaccional.Colectivo c\n",
    "    JOIN transaccional.linea_vehiculo l ON c.id_colectivo = l.vehiculo_id \n",
    "    JOIN transaccional.linea li ON l.linea_id = li.id_linea;\n",
    "\"\"\")\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexión\n",
    "conexion.commit()\n",
    "cursor.close()\n",
    "conexion.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMENSION FECHA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### **Cargamos dimension fecha**\n",
    "# Configuración de la conexión a la base de datos\n",
    "conexion = psycopg2.connect(\n",
    "    dbname=\"Parada_1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"1234\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Ejecutar la consulta para insertar datos en la tabla `dim_fecha`\n",
    "cursor.execute(\"\"\"\n",
    "    INSERT INTO \"CuboMultidimensional\".dim_fecha (hora, dia, mes, ano)\n",
    "    SELECT DISTINCT \n",
    "        EXTRACT(HOUR FROM Fecha_llegada)::integer AS hora,\n",
    "        EXTRACT(DAY FROM Fecha_llegada) AS dia,\n",
    "        EXTRACT(MONTH FROM Fecha_llegada) AS mes,\n",
    "        EXTRACT(YEAR FROM Fecha_llegada) AS ano\n",
    "    FROM transaccional.Clientes;\n",
    "\"\"\")\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexión\n",
    "conexion.commit()\n",
    "cursor.close()\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Consulta intermedia del hecho**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeyer\\AppData\\Local\\Temp\\ipykernel_484\\1080848955.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_clientes = pd.read_sql(query, conexion)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# Configuración de la conexión a la base de datos\n",
    "conexion = psycopg2.connect(\n",
    "    dbname=\"Parada_1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"1234\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "\n",
    "# Consulta SQL para obtener fecha de llegada y código postal\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    AVG(EXTRACT(EPOCH FROM (c.Fecha_salida - c.Fecha_llegada)) / 60) AS avg_tiempo_espera,\n",
    "    COUNT(c.ID_Cliente) AS cantidad_personas_en_parada,\n",
    "    NULL AS id_clima,\n",
    "    dc.id_cliente,\n",
    "    co.id_colectivo,\n",
    "    dp.id_parada,\n",
    "    dp.localidad,\n",
    "    df.hora, df.dia, df.mes, df.ano\n",
    "FROM transaccional.Clientes c\n",
    "JOIN \"CuboMultidimensional\".dim_cliente dc ON dc.tipo_cliente = c.Tipo_de_Cliente\n",
    "JOIN transaccional.Parada p ON p.ID_Parada = c.ID_Parada\n",
    "JOIN \"CuboMultidimensional\".dim_parada dp ON dp.parada = p.nombre\n",
    "JOIN transaccional.Colectivo co ON co.ID_Colectivo = c.colectivo_id\n",
    "JOIN \"CuboMultidimensional\".dim_fecha df \n",
    "    ON df.dia = EXTRACT(DAY FROM c.Fecha_llegada)\n",
    "    AND df.mes = EXTRACT(MONTH FROM c.Fecha_llegada)\n",
    "    AND df.ano = EXTRACT(YEAR FROM c.Fecha_llegada)\n",
    "    AND df.hora = EXTRACT(HOUR FROM c.Fecha_llegada)\n",
    "JOIN transaccional.linea_vehiculo lv ON c.colectivo_id = lv.vehiculo_id\n",
    "-- Aquí se usa una subconsulta correlacionada para obtener la fecha_de_asignacion más cercana\n",
    "WHERE lv.fecha_de_asignacion = (\n",
    "    SELECT fecha_de_asignacion\n",
    "    FROM transaccional.linea_vehiculo lv_sub\n",
    "    WHERE lv_sub.vehiculo_id = c.colectivo_id\n",
    "    ORDER BY ABS(EXTRACT(EPOCH FROM (c.fecha_salida - lv_sub.fecha_de_asignacion)))\n",
    "    LIMIT 1\n",
    ")\n",
    "GROUP BY co.id_colectivo, dp.id_parada, dc.id_cliente, df.hora, df.dia, df.mes, df.ano;\n",
    "\"\"\"\n",
    "\n",
    "# Ejecuta la consulta y almacena el resultado en un DataFrame\n",
    "df_clientes = pd.read_sql(query, conexion)\n",
    "\n",
    "# Cierra la conexión después de obtener los datos\n",
    "\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conexion a la api para obtener los datos historicos del clima**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# URL para los datos históricos\u001b[39;00m\n\u001b[0;32m     12\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mubicacion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfecha_inicio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfecha_fin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?unitGroup=metric&key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&contentType=json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m ResultBytes \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Parsear los resultados como JSON\u001b[39;00m\n\u001b[0;32m     16\u001b[0m jsonData \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(ResultBytes)\n",
      "File \u001b[1;32mc:\\Users\\yeyer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yeyer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\yeyer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\yeyer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yeyer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\yeyer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 429: "
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Establece el rango de fechas en la URL para obtener datos históricos\n",
    "fecha_inicio = \"2023-11-01\"\n",
    "fecha_fin = \"2023-11-30\"\n",
    "ubicacion = \"parana\"\n",
    "api_key = \"63T8LGUCCM4NM8UZH9EBVZKBN\"\n",
    "\n",
    "# URL para los datos históricos\n",
    "url = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{ubicacion}/{fecha_inicio}/{fecha_fin}?unitGroup=metric&key={api_key}&contentType=json\"\n",
    "ResultBytes = urllib.request.urlopen(url)\n",
    "\n",
    "# Parsear los resultados como JSON\n",
    "jsonData = json.load(ResultBytes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cargamos los datos de la conexion y lo cargamos en un dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ubicacion       fecha      hora  temperatura       condiciones  humedad  \\\n",
      "0      parana  2023-10-01  00:00:00         11.6             Clear    53.23   \n",
      "1      parana  2023-10-01  01:00:00         11.3             Clear    54.53   \n",
      "2      parana  2023-10-01  02:00:00         10.6             Clear    55.80   \n",
      "3      parana  2023-10-01  03:00:00          9.9             Clear    57.95   \n",
      "4      parana  2023-10-01  04:00:00          9.4             Clear    60.88   \n",
      "..        ...         ...       ...          ...               ...      ...   \n",
      "715    parana  2023-10-30  19:00:00         17.0  Partially cloudy    70.49   \n",
      "716    parana  2023-10-30  20:00:00         16.9  Partially cloudy    69.35   \n",
      "717    parana  2023-10-30  21:00:00         16.4  Partially cloudy    71.69   \n",
      "718    parana  2023-10-30  22:00:00         15.9  Partially cloudy    71.42   \n",
      "719    parana  2023-10-30  23:00:00         15.7          Overcast    72.67   \n",
      "\n",
      "     viento  \n",
      "0       1.0  \n",
      "1       1.2  \n",
      "2       0.4  \n",
      "3       0.0  \n",
      "4       0.8  \n",
      "..      ...  \n",
      "715    25.9  \n",
      "716    25.7  \n",
      "717    25.7  \n",
      "718    20.5  \n",
      "719    14.8  \n",
      "\n",
      "[720 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Crear una lista para almacenar los datos de cada hora\n",
    "data = []\n",
    "\n",
    "# Recorre los datos JSON y extrae la información horaria\n",
    "for day in jsonData['days']:\n",
    "    fecha = day['datetime']\n",
    "    for hour in day['hours']:\n",
    "        # Extrae la información horaria y agrégala a la lista como un diccionario\n",
    "        data.append({\n",
    "            \"ubicacion\": ubicacion,\n",
    "            \"fecha\": fecha,\n",
    "            \"hora\": hour['datetime'],\n",
    "            \"temperatura\": hour['temp'],\n",
    "            \"condiciones\": hour['conditions'],\n",
    "            \"humedad\": hour['humidity'],\n",
    "            \"viento\": hour['windspeed']\n",
    "        })\n",
    "\n",
    "# Convertir la lista de datos en un DataFrame\n",
    "df_clima_historico = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(df_clima_historico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Procesamiento de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convertimos las columnas a datatime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               fecha_hora\n",
      "0     2023-11-03 00:00:00\n",
      "1     2023-11-04 00:00:00\n",
      "2     2023-11-07 00:00:00\n",
      "3     2023-11-12 00:00:00\n",
      "4     2023-11-20 00:00:00\n",
      "...                   ...\n",
      "69595 2023-11-24 22:00:00\n",
      "69596 2023-11-27 22:00:00\n",
      "69597 2023-11-01 23:00:00\n",
      "69598 2023-11-08 23:00:00\n",
      "69599 2023-11-28 23:00:00\n",
      "\n",
      "[69600 rows x 1 columns]\n",
      "             fecha_hora\n",
      "0   2023-10-01 00:00:00\n",
      "1   2023-10-01 01:00:00\n",
      "2   2023-10-01 02:00:00\n",
      "3   2023-10-01 03:00:00\n",
      "4   2023-10-01 04:00:00\n",
      "..                  ...\n",
      "715 2023-10-30 19:00:00\n",
      "716 2023-10-30 20:00:00\n",
      "717 2023-10-30 21:00:00\n",
      "718 2023-10-30 22:00:00\n",
      "719 2023-10-30 23:00:00\n",
      "\n",
      "[720 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Crear una nueva columna 'fecha_hora' combinando las columnas 'ano', 'mes', 'dia' y 'hora'\n",
    "df_clientes['fecha_hora'] = pd.to_datetime(\n",
    "\tdf_clientes['ano'].astype(str) + '-' +\n",
    "\tdf_clientes['mes'].astype(str).str.zfill(2) + '-' +\n",
    "\tdf_clientes['dia'].astype(str).str.zfill(2) + ' ' +\n",
    "\tdf_clientes['hora'].astype(str).str.zfill(2) + ':00:00'\n",
    ")\n",
    "\n",
    "# Mostrar el DataFrame con la nueva columna\n",
    "print(df_clientes[['fecha_hora']])\n",
    "\n",
    "# Convertir las columnas 'fecha' y 'hora' a un solo datetime\n",
    "df_clima_historico['fecha_hora'] = pd.to_datetime(df_clima_historico['fecha'] + ' ' + df_clima_historico['hora'])\n",
    "\n",
    "# Mostrar el DataFrame con la nueva columna\n",
    "print(df_clima_historico[['fecha_hora']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Buscamos en el dataframe clima historico de la api y sabemos la condicion sabiendo la fecha y hora - la ubicacion esta intrinsica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               fecha_hora     tipo_de_clima\n",
      "0     2023-11-03 00:00:00  Partially cloudy\n",
      "1     2023-11-04 00:00:00          Overcast\n",
      "2     2023-11-07 00:00:00             Clear\n",
      "3     2023-11-12 00:00:00             Clear\n",
      "4     2023-11-20 00:00:00             Clear\n",
      "...                   ...               ...\n",
      "69595 2023-11-24 22:00:00  Partially cloudy\n",
      "69596 2023-11-27 22:00:00          Overcast\n",
      "69597 2023-11-01 23:00:00             Clear\n",
      "69598 2023-11-08 23:00:00             Clear\n",
      "69599 2023-11-28 23:00:00             Clear\n",
      "\n",
      "[69600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Realizar un merge entre df_clientes y df_clima_historico basado en la columna 'fecha_hora'\n",
    "df_clientess = df_clientes.merge(df_clima_historico[['fecha_hora', 'condiciones']], on='fecha_hora', how='left')\n",
    "\n",
    "# Renombrar la columna 'condiciones' a 'tipo_de_clima'\n",
    "df_clientess.rename(columns={'condiciones': 'tipo_de_clima'}, inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_clientess[['fecha_hora', 'tipo_de_clima']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Codificamos a numeros la condicion climatica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Partially cloudy' 'Overcast' 'Clear' 'Rain']\n",
      "[3 1 2 4]\n"
     ]
    }
   ],
   "source": [
    "df_clientess['tipo_de_clima'].unique()\n",
    "\n",
    "df_clientess['tipo_de_clima'] = df_clientess['tipo_de_clima'].apply(lambda x: 'Rain' if 'Rain' in x else x)\n",
    "\n",
    "# Mostrar los valores únicos de la columna 'tipo_de_clima'\n",
    "print(df_clientess['tipo_de_clima'].unique())\n",
    "\n",
    "# Crear un diccionario para mapear las condiciones climáticas a números\n",
    "clima_mapping = {\n",
    "    'Overcast': 1,\n",
    "    'Clear': 2,\n",
    "    'Partially cloudy': 3,\n",
    "    'Rain': 4\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo a la columna 'tipo_de_clima'\n",
    "df_clientess['tipo_de_clima'] = df_clientess['tipo_de_clima'].map(clima_mapping)\n",
    "\n",
    "# Mostrar los valores únicos de la columna 'tipo_de_clima' después del mapeo\n",
    "print(df_clientess['tipo_de_clima'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traducimos las condiciones y creamos una nueva columna con la codificacion de los condiciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clear' 'Partially cloudy' 'Overcast' 'Rain, Overcast'\n",
      " 'Rain, Partially cloudy']\n",
      "['Clear' 'Partially cloudy' 'Overcast' 'Rain']\n",
      "             fecha_hora           condiciones\n",
      "0   2023-11-01 00:00:00             Despejado\n",
      "1   2023-11-01 01:00:00             Despejado\n",
      "2   2023-11-01 02:00:00             Despejado\n",
      "3   2023-11-01 03:00:00             Despejado\n",
      "4   2023-11-01 04:00:00             Despejado\n",
      "..                  ...                   ...\n",
      "715 2023-11-30 19:00:00  Parcialmente nublado\n",
      "716 2023-11-30 20:00:00  Parcialmente nublado\n",
      "717 2023-11-30 21:00:00  Parcialmente nublado\n",
      "718 2023-11-30 22:00:00  Parcialmente nublado\n",
      "719 2023-11-30 23:00:00               Nublado\n",
      "\n",
      "[720 rows x 2 columns]\n",
      "             fecha_hora           condiciones  condiciones_numericas\n",
      "0   2023-11-01 00:00:00             Despejado                      2\n",
      "1   2023-11-01 01:00:00             Despejado                      2\n",
      "2   2023-11-01 02:00:00             Despejado                      2\n",
      "3   2023-11-01 03:00:00             Despejado                      2\n",
      "4   2023-11-01 04:00:00             Despejado                      2\n",
      "..                  ...                   ...                    ...\n",
      "715 2023-11-30 19:00:00  Parcialmente nublado                      3\n",
      "716 2023-11-30 20:00:00  Parcialmente nublado                      3\n",
      "717 2023-11-30 21:00:00  Parcialmente nublado                      3\n",
      "718 2023-11-30 22:00:00  Parcialmente nublado                      3\n",
      "719 2023-11-30 23:00:00               Nublado                      1\n",
      "\n",
      "[720 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_clima_historico['condiciones'].unique())\n",
    "\n",
    "df_clima_historico['condiciones'] = df_clima_historico['condiciones'].apply(lambda x: 'Rain' if 'Rain' in x else x)\n",
    "\n",
    "# Mostrar los valores únicos de la columna 'tipo_de_clima'\n",
    "print(df_clima_historico['condiciones'].unique())\n",
    "\n",
    "# Diccionario de mapeo para traducir las condiciones climáticas al español\n",
    "traduccion_clima = {\n",
    "    'Overcast': 'Nublado',\n",
    "    'Clear': 'Despejado',\n",
    "    'Partially cloudy': 'Parcialmente nublado',\n",
    "    'Rain': 'Lluvia'\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo a la columna 'condiciones'\n",
    "df_clima_historico['condiciones'] = df_clima_historico['condiciones'].apply(lambda x: ', '.join([traduccion_clima.get(cond, cond) for cond in x.split(', ')]))\n",
    "\n",
    "# Mostrar el DataFrame con las condiciones traducidas\n",
    "print(df_clima_historico[['fecha_hora', 'condiciones']])\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "\n",
    "# Crear un diccionario para mapear las condiciones climáticas a números\n",
    "clima_mapping_es = {\n",
    "    'Nublado': 1,\n",
    "    'Despejado': 2,\n",
    "    'Parcialmente nublado': 3,\n",
    "    'Lluvia': 4\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo a la columna 'condiciones'\n",
    "df_clima_historico['condiciones_numericas'] = df_clima_historico['condiciones'].map(clima_mapping_es)\n",
    "\n",
    "# Mostrar el DataFrame con la nueva columna\n",
    "print(df_clima_historico[['fecha_hora', 'condiciones', 'condiciones_numericas']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reenombramos la columna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas para que coincidan con la tabla en la base de datos\n",
    "df_clima_historico = df_clima_historico.rename(columns={\n",
    "    'condiciones': 'tipo_de_clima',\n",
    "    'condiciones_numericas': 'id_clima'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cargamos la dim_clima**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la conexión a la base de datos\n",
    "conexion = psycopg2.connect(\n",
    "    dbname=\"Parada_1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"1234\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Inserta cada fila del DataFrame en la tabla `dim_clima`\n",
    "for _, row in df_clima_historico.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO \"CuboMultidimensional\".dim_clima (id_clima, condicion_climatica)\n",
    "        VALUES (%s, %s)\n",
    "        ON CONFLICT (id_clima) DO NOTHING;\n",
    "    \"\"\", (row['id_clima'], row['tipo_de_clima']))\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexión\n",
    "conexion.commit()\n",
    "cursor.close()\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cargamos en la tabla de hechos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la conexión a la base de datos\n",
    "conexion = psycopg2.connect(\n",
    "    dbname=\"Parada_1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"1234\",\n",
    "    host=\"localhost\"\n",
    ")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Inserta cada fila del DataFrame en la tabla `fact_transporte`\n",
    "for _, row in df_clientess.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO \"CuboMultidimensional\".fact_transporte (\n",
    "            avg_tiempo_espera, \n",
    "            cantidad_personas_en_parada, \n",
    "            id_cliente,\n",
    "            id_clima, \n",
    "            id_colectivo, \n",
    "            id_parada, \n",
    "            hora,\n",
    "            dia, \n",
    "            mes,\n",
    "            ano\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\", (\n",
    "        row['avg_tiempo_espera'], \n",
    "        row['cantidad_personas_en_parada'], \n",
    "        row['id_cliente'],\n",
    "        row['tipo_de_clima'], \n",
    "        row['id_colectivo'], \n",
    "        row['id_parada'], \n",
    "        row['hora'],\n",
    "        row['dia'],\n",
    "        row['mes'],\n",
    "        row['ano']    \n",
    "    ))\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexión\n",
    "conexion.commit()\n",
    "cursor.close()\n",
    "conexion.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
